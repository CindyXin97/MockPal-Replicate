import { neon } from '@neondatabase/serverless';
import dotenv from 'dotenv';

dotenv.config({ path: '.env.local' });
const sql = neon(process.env.DATABASE_URL!);

// SQLé¢˜ç›®çš„è¡¨ç»“æ„æ›´æ–°
const sqlTableUpdates = [
  {
    company: 'Meta',
    position: 'æ•°æ®åˆ†æå¸ˆ',
    questionPattern: 'ç¼–å†™SQLæŸ¥è¯¢æ¥è®¡ç®—ç”¨æˆ·ç•™å­˜ç‡',
    updatedQuestion: `**è¡¨ç»“æ„:**

\`\`\`sql
-- ç”¨æˆ·æ´»åŠ¨è¡¨
CREATE TABLE user_activity (
    user_id INTEGER,
    login_date DATE,
    session_duration INTEGER,  -- ä¼šè¯æ—¶é•¿(åˆ†é’Ÿ)
    pages_viewed INTEGER,
    actions_count INTEGER
);

-- ç¤ºä¾‹æ•°æ®
INSERT INTO user_activity VALUES 
(1001, '2024-01-01', 45, 12, 8),
(1001, '2024-01-02', 32, 8, 5),
(1001, '2024-01-08', 28, 6, 3),
(1002, '2024-01-01', 67, 15, 12),
(1002, '2024-01-02', 43, 9, 7),
(1003, '2024-01-15', 25, 5, 2),
(1003, '2024-01-16', 38, 11, 6);
\`\`\`

**é¢˜ç›®:** ç¼–å†™SQLæŸ¥è¯¢æ¥è®¡ç®—ç”¨æˆ·ç•™å­˜ç‡ï¼šè®¡ç®—æ¯ä¸ªæœˆæ–°æ³¨å†Œç”¨æˆ·åœ¨ç¬¬1ã€7ã€30å¤©çš„ç•™å­˜ç‡ã€‚`,
    updatedAnswer: `**è¡¨ç»“æ„è¯´æ˜:**
- user_activity: è®°å½•ç”¨æˆ·æ¯æ—¥ç™»å½•å’Œæ´»åŠ¨æ•°æ®
- user_id: ç”¨æˆ·å”¯ä¸€æ ‡è¯†
- login_date: ç™»å½•æ—¥æœŸ
- session_duration: ä¼šè¯æ—¶é•¿
- pages_viewed: æµè§ˆé¡µé¢æ•°
- actions_count: æ“ä½œæ¬¡æ•°

**SQLè§£å†³æ–¹æ¡ˆ:**

\`\`\`sql
-- ç”¨æˆ·ç•™å­˜ç‡åˆ†æ
WITH user_first_login AS (
    -- è·å–æ¯ä¸ªç”¨æˆ·çš„é¦–æ¬¡ç™»å½•æ—¥æœŸ
    SELECT 
        user_id,
        DATE(MIN(login_date)) AS first_login_date,
        DATE_TRUNC('month', MIN(login_date)) AS cohort_month
    FROM user_activity
    GROUP BY user_id
),

user_activity_with_cohort AS (
    -- å°†ç”¨æˆ·æ´»åŠ¨ä¸é¦–æ¬¡ç™»å½•æ—¥æœŸå…³è”
    SELECT 
        ua.user_id,
        ua.login_date,
        ufl.first_login_date,
        ufl.cohort_month,
        DATE_DIFF(ua.login_date, ufl.first_login_date, DAY) AS days_since_first_login
    FROM user_activity ua
    JOIN user_first_login ufl ON ua.user_id = ufl.user_id
),

retention_data AS (
    -- è®¡ç®—å„ä¸ªæ—¶é—´ç‚¹çš„ç•™å­˜ç”¨æˆ·
    SELECT 
        cohort_month,
        COUNT(DISTINCT user_id) AS total_users,
        COUNT(DISTINCT CASE WHEN days_since_first_login = 1 THEN user_id END) AS day_1_users,
        COUNT(DISTINCT CASE WHEN days_since_first_login = 7 THEN user_id END) AS day_7_users,
        COUNT(DISTINCT CASE WHEN days_since_first_login = 30 THEN user_id END) AS day_30_users
    FROM user_activity_with_cohort
    GROUP BY cohort_month
)

-- è®¡ç®—ç•™å­˜ç‡
SELECT 
    cohort_month,
    total_users,
    ROUND(day_1_users * 100.0 / total_users, 2) AS day_1_retention_rate,
    ROUND(day_7_users * 100.0 / total_users, 2) AS day_7_retention_rate,
    ROUND(day_30_users * 100.0 / total_users, 2) AS day_30_retention_rate
FROM retention_data
WHERE total_users >= 100
ORDER BY cohort_month;
\`\`\`

**å…³é”®æŠ€æœ¯ç‚¹:**
- DATE_TRUNC: æŒ‰æœˆåˆ†ç»„ç”¨æˆ·
- DATE_DIFF: è®¡ç®—æ—¥æœŸå·®å¼‚
- æ¡ä»¶èšåˆ: CASE WHENç»“åˆCOUNT
- çª—å£å‡½æ•°åº”ç”¨
- ç•™å­˜ç‡è®¡ç®—å…¬å¼`
  },
  {
    company: 'Google',
    position: 'æ•°æ®åˆ†æå¸ˆ',
    questionPattern: 'ç¼–å†™SQLæŸ¥è¯¢æ¥è¯†åˆ«å¼‚å¸¸çš„ç”¨æˆ·è¡Œä¸º',
    updatedQuestion: `**è¡¨ç»“æ„:**

\`\`\`sql
-- æœç´¢æ—¥å¿—è¡¨
CREATE TABLE search_logs (
    user_id INTEGER,
    search_timestamp TIMESTAMP,
    search_query VARCHAR(500),
    results_count INTEGER,
    clicked_result BOOLEAN,
    session_id VARCHAR(50)
);

-- ç¤ºä¾‹æ•°æ®
INSERT INTO search_logs VALUES 
(2001, '2024-01-15 09:30:00', 'machine learning tutorial', 1250, true, 'sess_001'),
(2001, '2024-01-15 09:31:00', 'python pandas', 890, true, 'sess_001'),
(2001, '2024-01-15 14:22:00', 'data science jobs', 2100, false, 'sess_002'),
(2002, '2024-01-15 10:15:00', 'weather today', 45, true, 'sess_003'),
(2002, '2024-01-15 10:15:30', 'weather', 52, false, 'sess_003'),
(2002, '2024-01-15 10:16:00', 'weather forecast', 38, true, 'sess_003'),
-- å¼‚å¸¸ç”¨æˆ·ç¤ºä¾‹
(2003, '2024-01-15 11:00:00', 'buy', 1000, false, 'sess_004'),
(2003, '2024-01-15 11:00:15', 'buy shoes', 800, false, 'sess_004'),
(2003, '2024-01-15 11:00:30', 'buy online', 950, false, 'sess_004');
\`\`\`

**é¢˜ç›®:** ç¼–å†™SQLæŸ¥è¯¢æ¥è¯†åˆ«å¼‚å¸¸çš„ç”¨æˆ·è¡Œä¸ºï¼šæ‰¾å‡ºæœç´¢é‡çªç„¶å¢åŠ è¶…è¿‡å¹³å‡æ°´å¹³3å€çš„ç”¨æˆ·ï¼Œå¹¶åˆ†æå…¶æœç´¢æ¨¡å¼ã€‚`,
    updatedAnswer: `**è¡¨ç»“æ„è¯´æ˜:**
- search_logs: ç”¨æˆ·æœç´¢è¡Œä¸ºæ—¥å¿—
- user_id: ç”¨æˆ·ID
- search_timestamp: æœç´¢æ—¶é—´æˆ³
- search_query: æœç´¢å…³é”®è¯
- results_count: æœç´¢ç»“æœæ•°é‡
- clicked_result: æ˜¯å¦ç‚¹å‡»ç»“æœ
- session_id: ä¼šè¯æ ‡è¯†

**SQLè§£å†³æ–¹æ¡ˆ:**

\`\`\`sql
-- å¼‚å¸¸ç”¨æˆ·æœç´¢è¡Œä¸ºåˆ†æ
WITH user_daily_searches AS (
    -- è®¡ç®—æ¯ä¸ªç”¨æˆ·æ¯å¤©çš„æœç´¢æ¬¡æ•°
    SELECT 
        user_id,
        DATE(search_timestamp) AS search_date,
        COUNT(*) AS daily_search_count,
        COUNT(DISTINCT search_query) AS unique_queries,
        AVG(LENGTH(search_query)) AS avg_query_length,
        COUNT(DISTINCT session_id) AS sessions_count
    FROM search_logs
    WHERE search_timestamp >= CURRENT_DATE - INTERVAL '30 days'
    GROUP BY user_id, DATE(search_timestamp)
),

user_search_stats AS (
    -- è®¡ç®—æ¯ä¸ªç”¨æˆ·çš„æœç´¢ç»Ÿè®¡ä¿¡æ¯
    SELECT 
        user_id,
        AVG(daily_search_count) AS avg_daily_searches,
        STDDEV(daily_search_count) AS stddev_daily_searches,
        MAX(daily_search_count) AS max_daily_searches,
        COUNT(*) AS active_days
    FROM user_daily_searches
    GROUP BY user_id
    HAVING COUNT(*) >= 7  -- è‡³å°‘æ´»è·ƒ7å¤©
),

anomalous_users AS (
    -- è¯†åˆ«å¼‚å¸¸ç”¨æˆ·
    SELECT 
        uss.user_id,
        uss.avg_daily_searches,
        uss.max_daily_searches,
        uds.search_date AS anomaly_date,
        uds.daily_search_count AS anomaly_search_count,
        ROUND(uds.daily_search_count / uss.avg_daily_searches, 2) AS search_multiplier,
        uds.unique_queries,
        uds.avg_query_length,
        uds.sessions_count
    FROM user_search_stats uss
    JOIN user_daily_searches uds ON uss.user_id = uds.user_id
    WHERE uds.daily_search_count > uss.avg_daily_searches * 3  -- è¶…è¿‡å¹³å‡3å€
        AND uss.avg_daily_searches >= 5  -- è¿‡æ»¤ä½é¢‘ç”¨æˆ·
),

search_pattern_analysis AS (
    -- åˆ†ææœç´¢æ¨¡å¼
    SELECT 
        au.user_id,
        au.anomaly_date,
        au.search_multiplier,
        COUNT(*) AS total_searches,
        COUNT(DISTINCT sl.search_query) AS unique_queries,
        AVG(LENGTH(sl.search_query)) AS avg_query_length,
        COUNT(DISTINCT EXTRACT(HOUR FROM sl.search_timestamp)) AS active_hours,
        SUM(CASE WHEN sl.clicked_result THEN 1 ELSE 0 END) AS clicked_searches,
        -- æœ€é¢‘ç¹çš„æœç´¢è¯
        STRING_AGG(DISTINCT sl.search_query ORDER BY sl.search_timestamp LIMIT 5) AS sample_queries
    FROM anomalous_users au
    JOIN search_logs sl ON au.user_id = sl.user_id 
        AND DATE(sl.search_timestamp) = au.anomaly_date
    GROUP BY au.user_id, au.anomaly_date, au.search_multiplier
)

-- æœ€ç»ˆç»“æœï¼šå¼‚å¸¸ç”¨æˆ·åŠå…¶æœç´¢æ¨¡å¼
SELECT 
    user_id,
    anomaly_date,
    search_multiplier,
    total_searches,
    unique_queries,
    ROUND(avg_query_length, 1) AS avg_query_length,
    active_hours,
    ROUND(clicked_searches * 100.0 / total_searches, 1) AS click_rate,
    sample_queries,
    -- å¼‚å¸¸æ¨¡å¼åˆ†ç±»
    CASE 
        WHEN active_hours <= 2 THEN 'Concentrated_Time'
        WHEN unique_queries * 1.0 / total_searches < 0.3 THEN 'Repetitive_Queries'
        WHEN avg_query_length < 3 THEN 'Short_Queries'
        WHEN clicked_searches * 1.0 / total_searches < 0.1 THEN 'Low_Click_Rate'
        ELSE 'Other_Pattern'
    END AS anomaly_pattern
FROM search_pattern_analysis
ORDER BY search_multiplier DESC, total_searches DESC;
\`\`\`

**å…³é”®æŠ€æœ¯ç‚¹:**
- æ—¶é—´åºåˆ—åˆ†æ: DATEå‡½æ•°æå–æ—¥æœŸ
- ç»Ÿè®¡åˆ†æ: AVG, STDDEVè®¡ç®—å¼‚å¸¸é˜ˆå€¼
- æ¨¡å¼è¯†åˆ«: å¤šç»´åº¦ç‰¹å¾åˆ†æ
- å­—ç¬¦ä¸²èšåˆ: STRING_AGGæ”¶é›†æ ·æœ¬
- æ¡ä»¶åˆ†ç±»: CASE WHENè¿›è¡Œæ¨¡å¼åˆ†ç±»`
  },
  {
    company: 'Amazon',
    position: 'æ•°æ®åˆ†æå¸ˆ',
    questionPattern: 'ç¼–å†™SQLæŸ¥è¯¢æ¥åˆ†æå•†å“æ¨èæ•ˆæœ',
    updatedQuestion: `**è¡¨ç»“æ„:**

\`\`\`sql
-- æ¨èè®°å½•è¡¨
CREATE TABLE recommendations (
    recommendation_id VARCHAR(50) PRIMARY KEY,
    user_id INTEGER,
    product_id INTEGER,
    recommendation_position INTEGER,  -- æ¨èä½ç½® 1-10
    recommendation_algorithm VARCHAR(50),  -- æ¨èç®—æ³•
    shown_timestamp TIMESTAMP
);

-- å•†å“ä¿¡æ¯è¡¨
CREATE TABLE products (
    product_id INTEGER PRIMARY KEY,
    product_name VARCHAR(200),
    category VARCHAR(50),
    price DECIMAL(10,2),
    brand VARCHAR(50)
);

-- ç‚¹å‡»è®°å½•è¡¨
CREATE TABLE clicks (
    click_id VARCHAR(50) PRIMARY KEY,
    recommendation_id VARCHAR(50),
    user_id INTEGER,
    clicked_timestamp TIMESTAMP,
    FOREIGN KEY (recommendation_id) REFERENCES recommendations(recommendation_id)
);

-- è®¢å•è¡¨
CREATE TABLE orders (
    order_id VARCHAR(50) PRIMARY KEY,
    user_id INTEGER,
    product_id INTEGER,
    quantity INTEGER,
    revenue DECIMAL(10,2),
    order_timestamp TIMESTAMP
);

-- ç¤ºä¾‹æ•°æ®
INSERT INTO products VALUES 
(101, 'iPhone 15', 'Electronics', 999.00, 'Apple'),
(102, 'Samsung Galaxy S24', 'Electronics', 899.00, 'Samsung'),
(201, 'Nike Air Max', 'Footwear', 120.00, 'Nike'),
(202, 'Adidas Ultraboost', 'Footwear', 180.00, 'Adidas');

INSERT INTO recommendations VALUES 
('rec_001', 3001, 101, 1, 'collaborative_filtering', '2024-01-15 10:00:00'),
('rec_002', 3001, 102, 2, 'collaborative_filtering', '2024-01-15 10:00:00'),
('rec_003', 3002, 201, 1, 'content_based', '2024-01-15 11:30:00');

INSERT INTO clicks VALUES 
('click_001', 'rec_001', 3001, '2024-01-15 10:05:00'),
('click_002', 'rec_003', 3002, '2024-01-15 11:35:00');

INSERT INTO orders VALUES 
('order_001', 3001, 101, 1, 999.00, '2024-01-15 14:20:00'),
('order_002', 3002, 201, 2, 240.00, '2024-01-16 09:15:00');
\`\`\`

**é¢˜ç›®:** ç¼–å†™SQLæŸ¥è¯¢æ¥åˆ†æå•†å“æ¨èæ•ˆæœï¼šè®¡ç®—æ¨èå•†å“çš„ç‚¹å‡»ç‡ã€è½¬åŒ–ç‡ï¼Œå¹¶æŒ‰å•†å“ç±»åˆ«å’Œæ¨èä½ç½®è¿›è¡Œåˆ†æã€‚`,
    updatedAnswer: `**è¡¨ç»“æ„è¯´æ˜:**
- recommendations: æ¨èå±•ç¤ºè®°å½•
- products: å•†å“åŸºæœ¬ä¿¡æ¯
- clicks: ç”¨æˆ·ç‚¹å‡»è®°å½•
- orders: è´­ä¹°è®¢å•è®°å½•

**å…³é”®å­—æ®µ:**
- recommendation_position: æ¨èä½ç½®(1-10)
- recommendation_algorithm: æ¨èç®—æ³•ç±»å‹
- æ—¶é—´å…³è”: ç‚¹å‡»éœ€åœ¨æ¨èå24å°æ—¶å†…ï¼Œè´­ä¹°éœ€åœ¨æ¨èå7å¤©å†…

**SQLè§£å†³æ–¹æ¡ˆ:**

\`\`\`sql
-- å•†å“æ¨èæ•ˆæœåˆ†æ
WITH recommendation_events AS (
    -- è·å–æ¨èå±•ç¤ºã€ç‚¹å‡»ã€è´­ä¹°äº‹ä»¶
    SELECT 
        r.recommendation_id,
        r.user_id,
        r.product_id,
        r.recommendation_position,
        r.recommendation_algorithm,
        r.shown_timestamp,
        p.category,
        p.price,
        p.brand,
        -- ç‚¹å‡»äº‹ä»¶ (24å°æ—¶å†…)
        c.clicked_timestamp,
        CASE WHEN c.clicked_timestamp IS NOT NULL THEN 1 ELSE 0 END AS clicked,
        -- è´­ä¹°äº‹ä»¶ (7å¤©å†…)
        o.order_timestamp,
        o.quantity,
        o.revenue,
        CASE WHEN o.order_timestamp IS NOT NULL THEN 1 ELSE 0 END AS converted
    FROM recommendations r
    LEFT JOIN products p ON r.product_id = p.product_id
    LEFT JOIN clicks c ON r.recommendation_id = c.recommendation_id
        AND c.clicked_timestamp BETWEEN r.shown_timestamp 
        AND r.shown_timestamp + INTERVAL '1 day'
    LEFT JOIN orders o ON r.user_id = o.user_id AND r.product_id = o.product_id
        AND o.order_timestamp BETWEEN r.shown_timestamp 
        AND r.shown_timestamp + INTERVAL '7 days'
    WHERE r.shown_timestamp >= CURRENT_DATE - INTERVAL '30 days'
),

recommendation_metrics AS (
    -- è®¡ç®—åŸºç¡€æŒ‡æ ‡
    SELECT 
        category,
        recommendation_position,
        recommendation_algorithm,
        COUNT(*) AS total_recommendations,
        SUM(clicked) AS total_clicks,
        SUM(converted) AS total_conversions,
        SUM(revenue) AS total_revenue,
        -- è®¡ç®—ç‡
        ROUND(SUM(clicked) * 100.0 / COUNT(*), 2) AS click_rate,
        ROUND(SUM(converted) * 100.0 / COUNT(*), 2) AS conversion_rate,
        ROUND(SUM(converted) * 100.0 / NULLIF(SUM(clicked), 0), 2) AS click_to_conversion_rate,
        -- æ”¶å…¥æŒ‡æ ‡
        ROUND(SUM(revenue) / COUNT(*), 2) AS revenue_per_recommendation,
        ROUND(SUM(revenue) / NULLIF(SUM(clicked), 0), 2) AS revenue_per_click,
        -- å¹³å‡å•†å“ä»·æ ¼
        ROUND(AVG(price), 2) AS avg_product_price
    FROM recommendation_events
    GROUP BY category, recommendation_position, recommendation_algorithm
),

position_performance AS (
    -- æ¨èä½ç½®æ•ˆæœåˆ†æ
    SELECT 
        recommendation_position,
        COUNT(*) AS total_recommendations,
        ROUND(AVG(click_rate), 2) AS avg_click_rate,
        ROUND(AVG(conversion_rate), 2) AS avg_conversion_rate,
        SUM(total_revenue) AS total_revenue,
        -- ä½ç½®æ’å
        RANK() OVER (ORDER BY AVG(click_rate) DESC) AS click_rate_rank,
        RANK() OVER (ORDER BY AVG(conversion_rate) DESC) AS conversion_rate_rank
    FROM recommendation_metrics
    GROUP BY recommendation_position
),

category_performance AS (
    -- å•†å“ç±»åˆ«æ•ˆæœåˆ†æ
    SELECT 
        category,
        COUNT(*) AS total_recommendations,
        ROUND(AVG(click_rate), 2) AS avg_click_rate,
        ROUND(AVG(conversion_rate), 2) AS avg_conversion_rate,
        SUM(total_revenue) AS total_revenue,
        ROUND(AVG(avg_product_price), 2) AS avg_price,
        -- ç±»åˆ«è¡¨ç°æ’å
        RANK() OVER (ORDER BY AVG(conversion_rate) DESC) AS performance_rank
    FROM recommendation_metrics
    GROUP BY category
)

-- ä¸»æŸ¥è¯¢ï¼šç»¼åˆæ¨èæ•ˆæœæŠ¥å‘Š
SELECT 
    rm.category,
    rm.recommendation_position,
    rm.recommendation_algorithm,
    rm.total_recommendations,
    rm.click_rate,
    rm.conversion_rate,
    rm.click_to_conversion_rate,
    rm.revenue_per_recommendation,
    rm.revenue_per_click,
    rm.avg_product_price,
    -- ä¸å¹³å‡æ°´å¹³å¯¹æ¯”
    ROUND(rm.click_rate - pp.avg_click_rate, 2) AS click_rate_vs_position_avg,
    ROUND(rm.conversion_rate - cp.avg_conversion_rate, 2) AS conversion_rate_vs_category_avg,
    -- æ•ˆæœè¯„çº§
    CASE 
        WHEN rm.click_rate > pp.avg_click_rate AND rm.conversion_rate > cp.avg_conversion_rate 
        THEN 'Excellent'
        WHEN rm.click_rate > pp.avg_click_rate OR rm.conversion_rate > cp.avg_conversion_rate 
        THEN 'Good'
        WHEN rm.click_rate > 1.0 AND rm.conversion_rate > 0.5 
        THEN 'Average'
        ELSE 'Poor'
    END AS performance_rating
FROM recommendation_metrics rm
LEFT JOIN position_performance pp ON rm.recommendation_position = pp.recommendation_position
LEFT JOIN category_performance cp ON rm.category = cp.category
WHERE rm.total_recommendations >= 50  -- è¿‡æ»¤æ ·æœ¬é‡å¤ªå°çš„ç»„åˆ
ORDER BY rm.conversion_rate DESC, rm.click_rate DESC;

-- è¡¥å……æŸ¥è¯¢ï¼šç®—æ³•æ•ˆæœå¯¹æ¯”
SELECT 
    recommendation_algorithm,
    COUNT(*) AS total_recommendations,
    ROUND(AVG(click_rate), 2) AS avg_click_rate,
    ROUND(AVG(conversion_rate), 2) AS avg_conversion_rate,
    ROUND(SUM(total_revenue), 2) AS total_revenue
FROM recommendation_metrics
GROUP BY recommendation_algorithm
ORDER BY avg_conversion_rate DESC;
\`\`\`

**å…³é”®æŠ€æœ¯ç‚¹:**
- å¤šè¡¨å…³è”: LEFT JOINå¤„ç†å¯é€‰äº‹ä»¶
- æ—¶é—´çª—å£: INTERVALæ§åˆ¶ç‚¹å‡»å’Œè½¬åŒ–æ—¶é—´èŒƒå›´
- æ¡ä»¶èšåˆ: SUM(CASE WHEN)è®¡ç®—è½¬åŒ–
- çª—å£å‡½æ•°: RANK()è¿›è¡Œæ’ååˆ†æ
- ç©ºå€¼å¤„ç†: NULLIFé¿å…é™¤é›¶é”™è¯¯
- æ€§èƒ½è¯„çº§: å¤šæ¡ä»¶CASE WHENåˆ†ç±»`
  },
  {
    company: 'TikTok',
    position: 'æ•°æ®åˆ†æå¸ˆ',
    questionPattern: 'ç¼–å†™SQLæŸ¥è¯¢æ¥åˆ†æè§†é¢‘ç—…æ¯’å¼ä¼ æ’­',
    updatedQuestion: `**è¡¨ç»“æ„:**

\`\`\`sql
-- è§†é¢‘åŸºç¡€ä¿¡æ¯è¡¨
CREATE TABLE videos (
    video_id VARCHAR(50) PRIMARY KEY,
    creator_id INTEGER,
    upload_timestamp TIMESTAMP,
    duration_seconds INTEGER,
    category VARCHAR(50),
    has_music BOOLEAN,
    hashtags_count INTEGER
);

-- è§†é¢‘è§‚çœ‹è®°å½•è¡¨
CREATE TABLE video_views (
    view_id VARCHAR(50) PRIMARY KEY,
    video_id VARCHAR(50),
    user_id INTEGER,
    view_timestamp TIMESTAMP,
    view_duration INTEGER,  -- è§‚çœ‹æ—¶é•¿(ç§’)
    liked BOOLEAN DEFAULT FALSE,
    shared BOOLEAN DEFAULT FALSE,
    commented BOOLEAN DEFAULT FALSE,
    FOREIGN KEY (video_id) REFERENCES videos(video_id)
);

-- åˆ†äº«ä¼ æ’­è¡¨
CREATE TABLE shares (
    share_id VARCHAR(50) PRIMARY KEY,
    video_id VARCHAR(50),
    user_id INTEGER,  -- åˆ†äº«è€…
    shared_timestamp TIMESTAMP,
    parent_share_id VARCHAR(50),  -- ä¸Šçº§åˆ†äº«IDï¼Œç”¨äºè¿½è¸ªä¼ æ’­é“¾
    platform VARCHAR(50),  -- åˆ†äº«å¹³å°
    FOREIGN KEY (video_id) REFERENCES videos(video_id),
    FOREIGN KEY (parent_share_id) REFERENCES shares(share_id)
);

-- åˆ›ä½œè€…ä¿¡æ¯è¡¨
CREATE TABLE creators (
    creator_id INTEGER PRIMARY KEY,
    follower_count INTEGER,
    verification_status BOOLEAN,
    account_age_days INTEGER
);

-- ç¤ºä¾‹æ•°æ®
INSERT INTO videos VALUES 
('vid_001', 5001, '2024-01-10 14:30:00', 15, 'Comedy', true, 5),
('vid_002', 5002, '2024-01-11 09:15:00', 30, 'Dance', true, 8),
('vid_003', 5003, '2024-01-12 16:45:00', 45, 'Educational', false, 3);

INSERT INTO creators VALUES 
(5001, 50000, true, 365),
(5002, 1200000, true, 730),
(5003, 8500, false, 120);

INSERT INTO video_views VALUES 
('view_001', 'vid_001', 6001, '2024-01-10 15:00:00', 15, true, true, false),
('view_002', 'vid_001', 6002, '2024-01-10 15:30:00', 12, true, false, true),
('view_003', 'vid_001', 6003, '2024-01-10 16:00:00', 15, false, true, false),
('view_004', 'vid_002', 6001, '2024-01-11 10:00:00', 30, true, true, false);

INSERT INTO shares VALUES 
('share_001', 'vid_001', 6001, '2024-01-10 15:05:00', NULL, 'TikTok'),
('share_002', 'vid_001', 6004, '2024-01-10 17:20:00', 'share_001', 'Instagram'),
('share_003', 'vid_001', 6005, '2024-01-10 19:15:00', 'share_002', 'Twitter');
\`\`\`

**é¢˜ç›®:** ç¼–å†™SQLæŸ¥è¯¢æ¥åˆ†æè§†é¢‘ç—…æ¯’å¼ä¼ æ’­ï¼šè¯†åˆ«ç—…æ¯’è§†é¢‘çš„ç‰¹å¾ï¼Œåˆ†æä¼ æ’­è·¯å¾„å’Œå½±å“å› å­ã€‚`,
    updatedAnswer: `**è¡¨ç»“æ„è¯´æ˜:**
- videos: è§†é¢‘åŸºç¡€ä¿¡æ¯
- video_views: è§‚çœ‹è¡Œä¸ºè®°å½•
- shares: åˆ†äº«ä¼ æ’­é“¾è®°å½•
- creators: åˆ›ä½œè€…ä¿¡æ¯

**å…³é”®å­—æ®µ:**
- parent_share_id: è¿½è¸ªåˆ†äº«ä¼ æ’­é“¾çš„å…³é”®å­—æ®µ
- view_duration vs duration_seconds: è®¡ç®—å®Œæˆç‡
- äº’åŠ¨æŒ‡æ ‡: liked, shared, commented

**SQLè§£å†³æ–¹æ¡ˆ:**

\`\`\`sql
-- è§†é¢‘ç—…æ¯’å¼ä¼ æ’­åˆ†æ
WITH video_metrics AS (
    -- è®¡ç®—è§†é¢‘çš„åŸºç¡€æŒ‡æ ‡
    SELECT 
        v.video_id,
        v.creator_id,
        v.upload_timestamp,
        v.duration_seconds,
        v.category,
        v.has_music,
        v.hashtags_count,
        -- è§‚çœ‹æŒ‡æ ‡
        COUNT(DISTINCT vw.user_id) AS unique_viewers,
        COUNT(vw.view_id) AS total_views,
        SUM(CASE WHEN vw.view_duration >= v.duration_seconds * 0.8 THEN 1 ELSE 0 END) AS completion_views,
        -- äº’åŠ¨æŒ‡æ ‡
        SUM(CASE WHEN vw.liked THEN 1 ELSE 0 END) AS total_likes,
        SUM(CASE WHEN vw.shared THEN 1 ELSE 0 END) AS total_shares,
        SUM(CASE WHEN vw.commented THEN 1 ELSE 0 END) AS total_comments,
        -- è®¡ç®—å‚ä¸ç‡å’Œå®Œæˆç‡
        ROUND(SUM(CASE WHEN vw.liked OR vw.shared OR vw.commented THEN 1 ELSE 0 END) * 100.0 / COUNT(vw.view_id), 2) AS engagement_rate,
        ROUND(SUM(CASE WHEN vw.view_duration >= v.duration_seconds * 0.8 THEN 1 ELSE 0 END) * 100.0 / COUNT(vw.view_id), 2) AS completion_rate,
        -- å¹³å‡è§‚çœ‹æ—¶é•¿
        ROUND(AVG(vw.view_duration), 1) AS avg_view_duration
    FROM videos v
    LEFT JOIN video_views vw ON v.video_id = vw.video_id
    WHERE v.upload_timestamp >= CURRENT_DATE - INTERVAL '30 days'
    GROUP BY v.video_id, v.creator_id, v.upload_timestamp, v.duration_seconds, v.category, v.has_music, v.hashtags_count
),

viral_videos AS (
    -- è¯†åˆ«ç—…æ¯’è§†é¢‘ï¼ˆå¤šç»´åº¦ç­›é€‰ï¼‰
    SELECT 
        vm.*,
        -- ç—…æ¯’æŒ‡æ•°è®¡ç®—
        ROUND(
            (LOG(GREATEST(unique_viewers, 1)) * 0.3 + 
             LOG(GREATEST(total_shares, 1)) * 0.4 + 
             engagement_rate * 0.2 + 
             completion_rate * 0.1), 2
        ) AS viral_score,
        -- åˆ†äº«ä¼ æ’­æ¯”
        ROUND(total_shares * 1.0 / GREATEST(unique_viewers, 1), 4) AS share_rate,
        -- ç—…æ¯’ç­‰çº§
        CASE 
            WHEN unique_viewers >= 1000000 AND total_shares >= 50000 THEN 'Super_Viral'
            WHEN unique_viewers >= 500000 AND total_shares >= 20000 THEN 'Highly_Viral' 
            WHEN unique_viewers >= 100000 AND total_shares >= 5000 THEN 'Viral'
            WHEN unique_viewers >= 10000 AND total_shares >= 500 THEN 'Trending'
            ELSE 'Normal'
        END AS viral_level
    FROM video_metrics vm
    WHERE unique_viewers >= 1000  -- åŸºç¡€é—¨æ§›
),

sharing_cascade AS (
    -- åˆ†æåˆ†äº«ä¼ æ’­é“¾ï¼ˆé€’å½’æŸ¥è¯¢ï¼‰
    WITH RECURSIVE share_tree AS (
        -- åˆå§‹åˆ†äº«ï¼ˆç›´æ¥ä»åŸè§†é¢‘åˆ†äº«ï¼‰
        SELECT 
            s.share_id,
            s.video_id,
            s.user_id AS sharer_id,
            s.shared_timestamp,
            0 AS cascade_level,
            CAST(s.user_id AS VARCHAR) AS sharing_path,
            s.platform
        FROM shares s
        JOIN viral_videos vv ON s.video_id = vv.video_id
        WHERE s.parent_share_id IS NULL
        
        UNION ALL
        
        -- é€’å½’ï¼šä»åˆ†äº«ä¸­å†åˆ†äº«
        SELECT 
            s.share_id,
            s.video_id,
            s.user_id AS sharer_id,
            s.shared_timestamp,
            st.cascade_level + 1,
            st.sharing_path || '->' || CAST(s.user_id AS VARCHAR),
            s.platform
        FROM shares s
        JOIN share_tree st ON s.parent_share_id = st.share_id
        WHERE st.cascade_level < 5  -- é™åˆ¶é€’å½’æ·±åº¦
    )
    
    SELECT 
        video_id,
        MAX(cascade_level) AS max_cascade_depth,
        COUNT(*) AS total_cascade_shares,
        COUNT(DISTINCT sharer_id) AS unique_sharers,
        COUNT(DISTINCT platform) AS platforms_used,
        -- æ¯å±‚åˆ†äº«æ•°é‡åˆ†å¸ƒ
        STRING_AGG(
            DISTINCT CONCAT('L', cascade_level, ':', COUNT(*) OVER (PARTITION BY video_id, cascade_level)), 
            ', ' ORDER BY cascade_level
        ) AS cascade_distribution
    FROM share_tree
    GROUP BY video_id
),

time_growth_analysis AS (
    -- åˆ†æè§†é¢‘å¢é•¿æ—¶é—´æ›²çº¿
    SELECT 
        vv.video_id,
        vv.upload_timestamp,
        -- æŒ‰å°æ—¶åˆ†ç»„è§‚çœ‹æ•°æ®
        DATE_TRUNC('hour', vw.view_timestamp) AS hour_bucket,
        COUNT(*) AS hourly_views,
        SUM(CASE WHEN vw.shared THEN 1 ELSE 0 END) AS hourly_shares,
        -- ç´¯è®¡è§‚çœ‹æ•°
        SUM(COUNT(*)) OVER (
            PARTITION BY vv.video_id 
            ORDER BY DATE_TRUNC('hour', vw.view_timestamp)
        ) AS cumulative_views,
        -- å¢é•¿ç‡
        LAG(COUNT(*)) OVER (
            PARTITION BY vv.video_id 
            ORDER BY DATE_TRUNC('hour', vw.view_timestamp)
        ) AS prev_hour_views
    FROM viral_videos vv
    JOIN video_views vw ON vv.video_id = vw.video_id
    WHERE vw.view_timestamp BETWEEN vv.upload_timestamp AND vv.upload_timestamp + INTERVAL '7 days'
    GROUP BY vv.video_id, vv.upload_timestamp, DATE_TRUNC('hour', vw.view_timestamp)
),

peak_growth_moments AS (
    -- è¯†åˆ«å¢é•¿å³°å€¼æ—¶åˆ»
    SELECT 
        video_id,
        hour_bucket AS peak_hour,
        hourly_views AS peak_hourly_views,
        ROUND((hourly_views - COALESCE(prev_hour_views, 0)) * 100.0 / GREATEST(COALESCE(prev_hour_views, 1), 1), 2) AS growth_rate,
        ROW_NUMBER() OVER (PARTITION BY video_id ORDER BY hourly_views DESC) AS peak_rank
    FROM time_growth_analysis
    WHERE prev_hour_views IS NOT NULL
)

-- ä¸»æŸ¥è¯¢ï¼šç—…æ¯’è§†é¢‘ç»¼åˆåˆ†æ
SELECT 
    vv.video_id,
    vv.viral_level,
    vv.viral_score,
    vv.category,
    vv.has_music,
    vv.hashtags_count,
    vv.duration_seconds,
    -- è§‚çœ‹æŒ‡æ ‡
    vv.unique_viewers,
    vv.total_views,
    vv.completion_rate,
    vv.engagement_rate,
    vv.share_rate,
    -- ä¼ æ’­ç‰¹å¾
    COALESCE(sc.max_cascade_depth, 0) AS max_cascade_depth,
    COALESCE(sc.total_cascade_shares, 0) AS total_cascade_shares,
    COALESCE(sc.platforms_used, 0) AS platforms_used,
    -- å¢é•¿ç‰¹å¾
    pgm.peak_hourly_views,
    pgm.growth_rate AS max_growth_rate,
    ROUND(EXTRACT(EPOCH FROM (pgm.peak_hour - vv.upload_timestamp))/3600, 1) AS hours_to_peak,
    -- åˆ›ä½œè€…å½±å“
    c.follower_count AS creator_followers,
    c.verification_status AS creator_verified,
    -- ç—…æ¯’ä¼ æ’­æ•ˆç‡
    ROUND(vv.total_shares * 1.0 / GREATEST(EXTRACT(EPOCH FROM (pgm.peak_hour - vv.upload_timestamp))/3600, 1), 2) AS shares_per_hour_to_peak
FROM viral_videos vv
LEFT JOIN sharing_cascade sc ON vv.video_id = sc.video_id
LEFT JOIN peak_growth_moments pgm ON vv.video_id = pgm.video_id AND pgm.peak_rank = 1
LEFT JOIN creators c ON vv.creator_id = c.creator_id
WHERE vv.viral_level IN ('Viral', 'Highly_Viral', 'Super_Viral', 'Trending')
ORDER BY vv.viral_score DESC;

-- ç—…æ¯’ç‰¹å¾æ€»ç»“
SELECT 
    viral_level,
    COUNT(*) AS video_count,
    ROUND(AVG(viral_score), 2) AS avg_viral_score,
    ROUND(AVG(share_rate), 4) AS avg_share_rate,
    ROUND(AVG(engagement_rate), 2) AS avg_engagement_rate,
    ROUND(AVG(completion_rate), 2) AS avg_completion_rate,
    ROUND(AVG(max_cascade_depth), 1) AS avg_cascade_depth,
    -- å†…å®¹ç‰¹å¾
    ROUND(AVG(CASE WHEN has_music THEN 1.0 ELSE 0.0 END) * 100, 1) AS music_percentage,
    ROUND(AVG(duration_seconds), 1) AS avg_duration,
    ROUND(AVG(hashtags_count), 1) AS avg_hashtags
FROM viral_videos vv
LEFT JOIN sharing_cascade sc ON vv.video_id = sc.video_id
WHERE vv.viral_level IN ('Viral', 'Highly_Viral', 'Super_Viral', 'Trending')
GROUP BY viral_level
ORDER BY avg_viral_score DESC;
\`\`\`

**å…³é”®æŠ€æœ¯ç‚¹:**
- é€’å½’CTE: WITH RECURSIVEè¿½è¸ªåˆ†äº«ä¼ æ’­é“¾
- çª—å£å‡½æ•°: ç´¯è®¡è®¡ç®—å’Œæ’ååˆ†æ
- æ—¶é—´åºåˆ—: DATE_TRUNCæŒ‰å°æ—¶åˆ†ç»„
- ç—…æ¯’æŒ‡æ•°: LOGå‡½æ•°å¤„ç†æŒ‡æ•°å¢é•¿ç‰¹å¾
- å¤šç»´åˆ†æ: ç»“åˆå†…å®¹ã€ä¼ æ’­ã€æ—¶é—´ä¸‰ä¸ªç»´åº¦
- ç©ºå€¼å¤„ç†: COALESCEå’ŒGREATESTå¤„ç†è¾¹ç•Œæƒ…å†µ`
  },
  {
    company: 'LinkedIn',
    position: 'æ•°æ®åˆ†æå¸ˆ',
    questionPattern: 'ç¼–å†™SQLæŸ¥è¯¢æ¥åˆ†æèŒä½æ¨èçš„ç²¾å‡†åº¦',
    updatedQuestion: `**è¡¨ç»“æ„:**

\`\`\`sql
-- ç”¨æˆ·æŠ€èƒ½è¡¨
CREATE TABLE user_skills (
    user_id INTEGER,
    skill_name VARCHAR(100),
    proficiency_level INTEGER,  -- 1-5çº§
    years_experience INTEGER,
    is_certified BOOLEAN,
    is_active BOOLEAN DEFAULT TRUE
);

-- èŒä½æŠ€èƒ½è¦æ±‚è¡¨
CREATE TABLE job_skill_requirements (
    job_id INTEGER,
    required_skill VARCHAR(100),
    importance_level INTEGER,  -- 1-5, 5æœ€é‡è¦
    min_years_required INTEGER,
    is_mandatory BOOLEAN DEFAULT FALSE
);

-- èŒä½ä¿¡æ¯è¡¨
CREATE TABLE jobs (
    job_id INTEGER PRIMARY KEY,
    job_title VARCHAR(200),
    company_name VARCHAR(100),
    location VARCHAR(100),
    salary_range VARCHAR(50),
    job_level VARCHAR(50)  -- Entry, Mid, Senior
);

-- æ¨èè®°å½•è¡¨
CREATE TABLE recommendations (
    recommendation_id VARCHAR(50) PRIMARY KEY,
    user_id INTEGER,
    job_id INTEGER,
    recommendation_score DECIMAL(3,2),  -- 0.00-1.00
    recommended_timestamp TIMESTAMP,
    algorithm_version VARCHAR(20)
);

-- ç”¨æˆ·è¡Œä¸ºè¡¨
CREATE TABLE user_actions (
    action_id VARCHAR(50) PRIMARY KEY,
    recommendation_id VARCHAR(50),
    user_id INTEGER,
    job_id INTEGER,
    action_type VARCHAR(20),  -- 'click', 'apply', 'save'
    action_timestamp TIMESTAMP,
    FOREIGN KEY (recommendation_id) REFERENCES recommendations(recommendation_id)
);

-- ç”¨æˆ·åé¦ˆè¡¨
CREATE TABLE user_feedback (
    feedback_id VARCHAR(50) PRIMARY KEY,
    recommendation_id VARCHAR(50),
    user_id INTEGER,
    relevance_rating INTEGER,  -- 1-5åˆ†
    interest_level INTEGER,    -- 1-5åˆ†
    feedback_text TEXT,
    feedback_timestamp TIMESTAMP,
    FOREIGN KEY (recommendation_id) REFERENCES recommendations(recommendation_id)
);

-- ç”³è¯·ç»“æœè¡¨
CREATE TABLE application_results (
    application_id VARCHAR(50) PRIMARY KEY,
    user_id INTEGER,
    job_id INTEGER,
    applied_timestamp TIMESTAMP,
    result_status VARCHAR(20),  -- 'pending', 'interviewed', 'hired', 'rejected'
    result_timestamp TIMESTAMP
);

-- ç¤ºä¾‹æ•°æ®
INSERT INTO jobs VALUES 
(1001, 'Senior Data Scientist', 'Meta', 'San Francisco', '$150k-200k', 'Senior'),
(1002, 'Data Analyst', 'Google', 'Mountain View', '$120k-150k', 'Mid'),
(1003, 'ML Engineer', 'Amazon', 'Seattle', '$140k-180k', 'Senior');

INSERT INTO user_skills VALUES 
(7001, 'Python', 4, 5, true, true),
(7001, 'SQL', 5, 6, false, true),
(7001, 'Machine Learning', 4, 4, true, true),
(7001, 'Statistics', 3, 3, false, true),
(7002, 'Python', 3, 2, false, true),
(7002, 'SQL', 4, 3, true, true),
(7002, 'Tableau', 4, 3, true, true);

INSERT INTO job_skill_requirements VALUES 
(1001, 'Python', 5, 3, true),
(1001, 'Machine Learning', 5, 3, true),
(1001, 'Statistics', 4, 2, false),
(1001, 'Deep Learning', 3, 2, false),
(1002, 'SQL', 5, 2, true),
(1002, 'Python', 4, 1, false),
(1002, 'Tableau', 4, 2, false);

INSERT INTO recommendations VALUES 
('rec_001', 7001, 1001, 0.92, '2024-01-15 09:00:00', 'v2.1'),
('rec_002', 7001, 1002, 0.78, '2024-01-15 09:00:00', 'v2.1'),
('rec_003', 7002, 1002, 0.85, '2024-01-15 10:30:00', 'v2.1');

INSERT INTO user_actions VALUES 
('action_001', 'rec_001', 7001, 1001, 'click', '2024-01-15 09:15:00'),
('action_002', 'rec_001', 7001, 1001, 'apply', '2024-01-15 14:30:00'),
('action_003', 'rec_003', 7002, 1002, 'click', '2024-01-15 10:45:00');

INSERT INTO user_feedback VALUES 
('fb_001', 'rec_001', 7001, 5, 5, 'Perfect match for my skills', '2024-01-15 16:00:00'),
('fb_002', 'rec_002', 7001, 3, 2, 'Too junior for my experience', '2024-01-15 16:05:00');

INSERT INTO application_results VALUES 
('app_001', 7001, 1001, '2024-01-15 14:30:00', 'interviewed', '2024-01-20 10:00:00');
\`\`\`

**é¢˜ç›®:** ç¼–å†™SQLæŸ¥è¯¢æ¥åˆ†æèŒä½æ¨èçš„ç²¾å‡†åº¦ï¼šè®¡ç®—æ¨èå‡†ç¡®ç‡ï¼Œåˆ†æç”¨æˆ·æŠ€èƒ½åŒ¹é…åº¦å¯¹æ¨èæ•ˆæœçš„å½±å“ã€‚`,
    updatedAnswer: `**è¡¨ç»“æ„è¯´æ˜:**
- user_skills: ç”¨æˆ·æŠ€èƒ½æ¡£æ¡ˆ
- job_skill_requirements: èŒä½æŠ€èƒ½è¦æ±‚
- recommendations: æ¨èè®°å½•
- user_actions: ç”¨æˆ·è¡Œä¸º(ç‚¹å‡»ã€ç”³è¯·ã€æ”¶è—)
- user_feedback: ç”¨æˆ·ä¸»è§‚åé¦ˆ
- application_results: ç”³è¯·ç»“æœè·Ÿè¸ª

**å…³é”®å­—æ®µ:**
- proficiency_level & importance_level: æŠ€èƒ½ç†Ÿç»ƒåº¦å’Œé‡è¦æ€§(1-5çº§)
- recommendation_score: ç®—æ³•æ¨èåˆ†æ•°(0-1)
- is_mandatory: æ˜¯å¦ä¸ºå¿…éœ€æŠ€èƒ½

**SQLè§£å†³æ–¹æ¡ˆ:**

\`\`\`sql
-- èŒä½æ¨èç²¾å‡†åº¦åˆ†æ
WITH user_skill_profile AS (
    -- ç”¨æˆ·æŠ€èƒ½æ¡£æ¡ˆ
    SELECT 
        user_id,
        skill_name,
        proficiency_level,
        years_experience,
        is_certified,
        -- æŠ€èƒ½ç»¼åˆè¯„åˆ†
        ROUND(
            proficiency_level * 0.4 + 
            LEAST(years_experience, 10) * 0.4 + 
            CASE WHEN is_certified THEN 2 ELSE 0 END, 2
        ) AS skill_composite_score
    FROM user_skills
    WHERE is_active = true
),

job_requirement_profile AS (
    -- èŒä½è¦æ±‚æ¡£æ¡ˆ
    SELECT 
        job_id,
        required_skill,
        importance_level,
        min_years_required,
        is_mandatory,
        -- è¦æ±‚æƒé‡åˆ†æ•°
        importance_level * CASE WHEN is_mandatory THEN 2 ELSE 1 END AS requirement_weight
    FROM job_skill_requirements
),

recommendation_events AS (
    -- æ¨èäº‹ä»¶åŠç”¨æˆ·åé¦ˆ
    SELECT 
        r.recommendation_id,
        r.user_id,
        r.job_id,
        r.recommendation_score,
        r.recommended_timestamp,
        r.algorithm_version,
        j.job_title,
        j.company_name,
        j.job_level,
        -- ç”¨æˆ·è¡Œä¸ºæ±‡æ€»
        MAX(CASE WHEN ua.action_type = 'click' THEN 1 ELSE 0 END) AS clicked,
        MAX(CASE WHEN ua.action_type = 'apply' THEN 1 ELSE 0 END) AS applied,
        MAX(CASE WHEN ua.action_type = 'save' THEN 1 ELSE 0 END) AS saved,
        -- ç”¨æˆ·åé¦ˆ
        uf.relevance_rating,
        uf.interest_level,
        -- ç”³è¯·ç»“æœ
        ar.result_status,
        CASE WHEN ar.result_status IN ('interviewed', 'hired') THEN 1 ELSE 0 END AS positive_outcome
    FROM recommendations r
    LEFT JOIN jobs j ON r.job_id = j.job_id
    LEFT JOIN user_actions ua ON r.recommendation_id = ua.recommendation_id
    LEFT JOIN user_feedback uf ON r.recommendation_id = uf.recommendation_id
    LEFT JOIN application_results ar ON r.user_id = ar.user_id AND r.job_id = ar.job_id
        AND ar.applied_timestamp BETWEEN r.recommended_timestamp AND r.recommended_timestamp + INTERVAL '30 days'
    WHERE r.recommended_timestamp >= CURRENT_DATE - INTERVAL '30 days'
    GROUP BY r.recommendation_id, r.user_id, r.job_id, r.recommendation_score, 
             r.recommended_timestamp, r.algorithm_version, j.job_title, j.company_name, 
             j.job_level, uf.relevance_rating, uf.interest_level, ar.result_status
),

skill_matching_analysis AS (
    -- æŠ€èƒ½åŒ¹é…åº¦åˆ†æ
    SELECT 
        re.recommendation_id,
        re.user_id,
        re.job_id,
        -- æŠ€èƒ½åŒ¹é…ç»Ÿè®¡
        COUNT(jrp.required_skill) AS total_required_skills,
        COUNT(usp.skill_name) AS matched_skills,
        COUNT(CASE WHEN jrp.is_mandatory THEN 1 END) AS mandatory_skills,
        COUNT(CASE WHEN jrp.is_mandatory AND usp.skill_name IS NOT NULL THEN 1 END) AS matched_mandatory_skills,
        -- åŸºç¡€åŒ¹é…ç‡
        ROUND(COUNT(usp.skill_name) * 100.0 / GREATEST(COUNT(jrp.required_skill), 1), 2) AS basic_match_percentage,
        -- å¿…éœ€æŠ€èƒ½åŒ¹é…ç‡
        ROUND(
            COUNT(CASE WHEN jrp.is_mandatory AND usp.skill_name IS NOT NULL THEN 1 END) * 100.0 / 
            GREATEST(COUNT(CASE WHEN jrp.is_mandatory THEN 1 END), 1), 2
        ) AS mandatory_match_percentage,
        -- ç»éªŒåŒ¹é…åº¦
        ROUND(
            AVG(CASE 
                WHEN usp.skill_name IS NOT NULL THEN 
                    CASE WHEN usp.years_experience >= jrp.min_years_required THEN 100 ELSE 
                         (usp.years_experience * 100.0 / jrp.min_years_required) 
                    END
                ELSE 0 
            END), 2
        ) AS experience_match_percentage,
        -- åŠ æƒåŒ¹é…åº¦ï¼ˆè€ƒè™‘æŠ€èƒ½é‡è¦æ€§ï¼‰
        ROUND(
            SUM(CASE 
                WHEN usp.skill_name IS NOT NULL THEN 
                    LEAST(usp.skill_composite_score / 10.0, 1.0) * jrp.requirement_weight
                ELSE 0 
            END) * 100.0 / GREATEST(SUM(jrp.requirement_weight), 1), 2
        ) AS weighted_match_percentage,
        -- æŠ€èƒ½è¶…å‡ºåº¦ï¼ˆç”¨æˆ·æŠ€èƒ½è¶…å‡ºè¦æ±‚çš„ç¨‹åº¦ï¼‰
        ROUND(
            AVG(CASE 
                WHEN usp.skill_name IS NOT NULL AND jrp.min_years_required > 0 THEN
                    GREATEST((usp.years_experience - jrp.min_years_required) * 1.0 / jrp.min_years_required, 0)
                ELSE 0
            END) * 100, 2
        ) AS skill_exceeds_percentage
    FROM recommendation_events re
    LEFT JOIN job_requirement_profile jrp ON re.job_id = jrp.job_id
    LEFT JOIN user_skill_profile usp ON re.user_id = usp.user_id AND jrp.required_skill = usp.skill_name
    GROUP BY re.recommendation_id, re.user_id, re.job_id
),

recommendation_success_metrics AS (
    -- æ¨èæˆåŠŸåº¦é‡
    SELECT 
        re.*,
        sma.total_required_skills,
        sma.matched_skills,
        sma.basic_match_percentage,
        sma.mandatory_match_percentage,
        sma.experience_match_percentage,
        sma.weighted_match_percentage,
        sma.skill_exceeds_percentage,
        -- å®šä¹‰æ¨èæˆåŠŸçš„å¤šä¸ªæ ‡å‡†
        CASE 
            WHEN re.positive_outcome = 1 THEN 'Hired/Interviewed'
            WHEN re.applied = 1 THEN 'Applied'  
            WHEN re.clicked = 1 AND re.relevance_rating >= 4 THEN 'Highly_Relevant_Click'
            WHEN re.clicked = 1 AND re.relevance_rating >= 3 THEN 'Relevant_Click'
            WHEN re.clicked = 1 THEN 'Click_Only'
            WHEN re.saved = 1 THEN 'Saved_Only'
            ELSE 'No_Engagement'
        END AS outcome_category,
        -- ç»¼åˆæˆåŠŸè¯„åˆ† (0-100)
        CASE 
            WHEN re.positive_outcome = 1 THEN 100
            WHEN re.applied = 1 THEN 80
            WHEN re.clicked = 1 AND re.relevance_rating >= 4 THEN 70
            WHEN re.clicked = 1 AND re.relevance_rating >= 3 THEN 50
            WHEN re.clicked = 1 THEN 30
            WHEN re.saved = 1 THEN 20
            ELSE 0
        END AS success_score
    FROM recommendation_events re
    JOIN skill_matching_analysis sma ON re.recommendation_id = sma.recommendation_id
),

match_score_analysis AS (
    -- æŒ‰åŒ¹é…åº¦åˆ†æ¡¶åˆ†æ
    SELECT 
        -- åŒ¹é…åº¦åˆ†æ¡¶
        CASE 
            WHEN weighted_match_percentage >= 90 THEN '90-100%'
            WHEN weighted_match_percentage >= 80 THEN '80-89%'
            WHEN weighted_match_percentage >= 70 THEN '70-79%'
            WHEN weighted_match_percentage >= 60 THEN '60-69%'
            WHEN weighted_match_percentage >= 50 THEN '50-59%'
            ELSE '<50%'
        END AS match_score_bucket,
        -- å¿…éœ€æŠ€èƒ½åŒ¹é…åˆ†æ¡¶
        CASE 
            WHEN mandatory_match_percentage = 100 THEN 'All_Mandatory'
            WHEN mandatory_match_percentage >= 80 THEN 'Most_Mandatory'
            WHEN mandatory_match_percentage >= 50 THEN 'Some_Mandatory'
            ELSE 'Few_Mandatory'
        END AS mandatory_match_bucket,
        outcome_category,
        COUNT(*) AS recommendation_count,
        ROUND(AVG(success_score), 2) AS avg_success_score,
        ROUND(AVG(relevance_rating), 2) AS avg_relevance_rating,
        ROUND(AVG(recommendation_score), 3) AS avg_algorithm_score
    FROM recommendation_success_metrics
    WHERE relevance_rating IS NOT NULL  -- åªåˆ†ææœ‰åé¦ˆçš„æ¨è
    GROUP BY 
        CASE 
            WHEN weighted_match_percentage >= 90 THEN '90-100%'
            WHEN weighted_match_percentage >= 80 THEN '80-89%'
            WHEN weighted_match_percentage >= 70 THEN '70-79%'
            WHEN weighted_match_percentage >= 60 THEN '60-69%'
            WHEN weighted_match_percentage >= 50 THEN '50-59%'
            ELSE '<50%'
        END,
        CASE 
            WHEN mandatory_match_percentage = 100 THEN 'All_Mandatory'
            WHEN mandatory_match_percentage >= 80 THEN 'Most_Mandatory'
            WHEN mandatory_match_percentage >= 50 THEN 'Some_Mandatory'
            ELSE 'Few_Mandatory'
        END,
        outcome_category
)

-- ä¸»æŸ¥è¯¢ï¼šæ¨èç²¾å‡†åº¦ç»¼åˆåˆ†æ
SELECT 
    match_score_bucket,
    mandatory_match_bucket,
    SUM(recommendation_count) AS total_recommendations,
    -- å„ç±»ç»“æœçš„åˆ†å¸ƒ
    SUM(CASE WHEN outcome_category = 'Hired/Interviewed' THEN recommendation_count ELSE 0 END) AS hired_interviewed_count,
    SUM(CASE WHEN outcome_category = 'Applied' THEN recommendation_count ELSE 0 END) AS applied_count,
    SUM(CASE WHEN outcome_category LIKE '%Click%' THEN recommendation_count ELSE 0 END) AS clicked_count,
    SUM(CASE WHEN outcome_category = 'Saved_Only' THEN recommendation_count ELSE 0 END) AS saved_count,
    -- è®¡ç®—æˆåŠŸç‡
    ROUND(SUM(CASE WHEN outcome_category = 'Hired/Interviewed' THEN recommendation_count ELSE 0 END) * 100.0 / SUM(recommendation_count), 2) AS hire_interview_rate,
    ROUND(SUM(CASE WHEN outcome_category IN ('Applied', 'Hired/Interviewed') THEN recommendation_count ELSE 0 END) * 100.0 / SUM(recommendation_count), 2) AS application_rate,
    ROUND(SUM(CASE WHEN outcome_category NOT IN ('No_Engagement') THEN recommendation_count ELSE 0 END) * 100.0 / SUM(recommendation_count), 2) AS engagement_rate,
    -- å¹³å‡è¯„åˆ†
    ROUND(SUM(avg_success_score * recommendation_count) / SUM(recommendation_count), 2) AS weighted_avg_success_score,
    ROUND(SUM(avg_relevance_rating * recommendation_count) / SUM(recommendation_count), 2) AS weighted_avg_relevance,
    ROUND(SUM(avg_algorithm_score * recommendation_count) / SUM(recommendation_count), 3) AS weighted_avg_algorithm_score
FROM match_score_analysis
GROUP BY match_score_bucket, mandatory_match_bucket
ORDER BY 
    CASE match_score_bucket
        WHEN '90-100%' THEN 1
        WHEN '80-89%' THEN 2  
        WHEN '70-79%' THEN 3
        WHEN '60-69%' THEN 4
        WHEN '50-59%' THEN 5
        WHEN '<50%' THEN 6
    END,
    CASE mandatory_match_bucket
        WHEN 'All_Mandatory' THEN 1
        WHEN 'Most_Mandatory' THEN 2
        WHEN 'Some_Mandatory' THEN 3
        WHEN 'Few_Mandatory' THEN 4
    END;

-- è¡¥å……åˆ†æï¼šæŠ€èƒ½åŒ¹é…åº¦ä¸æ¨èæ•ˆæœçš„ç›¸å…³æ€§
WITH correlation_data AS (
    SELECT 
        recommendation_id,
        weighted_match_percentage,
        mandatory_match_percentage,
        experience_match_percentage,
        success_score,
        relevance_rating,
        recommendation_score
    FROM recommendation_success_metrics
    WHERE relevance_rating IS NOT NULL
)

SELECT 
    'Skill_Match_Correlation' AS analysis_type,
    ROUND(CORR(weighted_match_percentage, success_score), 3) AS skill_success_correlation,
    ROUND(CORR(mandatory_match_percentage, success_score), 3) AS mandatory_success_correlation,
    ROUND(CORR(experience_match_percentage, success_score), 3) AS experience_success_correlation,
    ROUND(CORR(weighted_match_percentage, relevance_rating), 3) AS skill_relevance_correlation,
    ROUND(CORR(recommendation_score, success_score), 3) AS algorithm_success_correlation,
    COUNT(*) AS sample_size
FROM correlation_data;

-- ç®—æ³•ç‰ˆæœ¬æ•ˆæœå¯¹æ¯”
SELECT 
    algorithm_version,
    COUNT(*) AS total_recommendations,
    ROUND(AVG(weighted_match_percentage), 2) AS avg_skill_match,
    ROUND(AVG(success_score), 2) AS avg_success_score,
    ROUND(AVG(relevance_rating), 2) AS avg_relevance_rating,
    ROUND(SUM(CASE WHEN applied = 1 THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) AS application_rate
FROM recommendation_success_metrics
WHERE relevance_rating IS NOT NULL
GROUP BY algorithm_version
ORDER BY avg_success_score DESC;
\`\`\`

**å…³é”®æŠ€æœ¯ç‚¹:**
- å¤šç»´æŠ€èƒ½åŒ¹é…: åŸºç¡€åŒ¹é…ã€å¿…éœ€æŠ€èƒ½ã€ç»éªŒè¦æ±‚ã€åŠ æƒåŒ¹é…
- æˆåŠŸåº¦é‡: å¤šå±‚æ¬¡å®šä¹‰æ¨èæˆåŠŸ(ç‚¹å‡»â†’ç”³è¯·â†’é¢è¯•â†’å½•ç”¨)
- ç›¸å…³æ€§åˆ†æ: CORRå‡½æ•°è®¡ç®—åŒ¹é…åº¦ä¸æˆåŠŸç‡ç›¸å…³æ€§
- åˆ†æ¡¶åˆ†æ: æŒ‰åŒ¹é…åº¦åŒºé—´åˆ†ææ¨èæ•ˆæœ
- ç»¼åˆè¯„åˆ†: è€ƒè™‘æŠ€èƒ½ç†Ÿç»ƒåº¦ã€è®¤è¯ã€ç»éªŒçš„ç»¼åˆè¯„åˆ†
- æ—¶é—´çª—å£: åˆç†è®¾ç½®è¡Œä¸ºè¿½è¸ªæ—¶é—´èŒƒå›´(30å¤©)`
  }
];

async function updateSqlQuestionsWithTables() {
  console.log('ğŸ”§ å¼€å§‹ä¸ºSQLé¢˜ç›®æ·»åŠ è¯¦ç»†è¡¨ç»“æ„...\n');
  
  try {
    let updatedCount = 0;
    
    for (const update of sqlTableUpdates) {
      console.log(`ğŸ“ æ›´æ–° ${update.company} - ${update.position} çš„SQLé¢˜ç›®...`);
      
      const result = await sql`
        UPDATE interview_questions 
        SET 
          question = ${update.updatedQuestion},
          recommended_answer = ${update.updatedAnswer}
        WHERE company = ${update.company} 
          AND position = ${update.position}
          AND question_type = 'technical'
          AND question LIKE ${`%${update.questionPattern}%`}
      `;
      
      console.log(`âœ… å·²æ›´æ–° ${update.company} - ${update.position}`);
      updatedCount++;
    }
    
    console.log(`\nğŸ‰ æˆåŠŸæ›´æ–° ${updatedCount} é“SQLé¢˜ç›®çš„è¡¨ç»“æ„ï¼\n`);
    
    // éªŒè¯æ›´æ–°ç»“æœ
    const sqlQuestions = await sql`
      SELECT company, position, LEFT(question, 100) as question_preview
      FROM interview_questions 
      WHERE question_type = 'technical' 
        AND (question LIKE '%CREATE TABLE%' OR question LIKE '%è¡¨ç»“æ„%')
      ORDER BY company, position
    `;
    
    console.log('ğŸ“Š å·²æ·»åŠ è¡¨ç»“æ„çš„SQLé¢˜ç›®:');
    sqlQuestions.forEach((q, i) => {
      console.log(`${i + 1}. ã€${q.company}ã€‘${q.position}`);
      console.log(`   ${q.question_preview}...\n`);
    });
    
  } catch (error) {
    console.error('âŒ æ›´æ–°è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯:', error);
  }
}

export { updateSqlQuestionsWithTables };

// å¦‚æœç›´æ¥è¿è¡Œæ­¤è„šæœ¬
if (require.main === module) {
  updateSqlQuestionsWithTables();
} 